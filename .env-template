## Set to "development" to trigger local development seed data rather than production, even in production NODE_ENV.
## This is rarely used.
PIPELINE_SEED_ENV=production

## Can be used to mark the pipeline as inactive
PIPELINE_IS_ACTIVE=1

## Logs from all services
PIPELINE_LOG_PATH=

## Core Services - Primarily making overrides available for exposed ports for multiple systems on a machine.
PIPELINE_DATABASE_PORT=
PIPELINE_MESSAGE_API_PORT=
PIPELINE_MESSAGE_UI_PORT=
PIPELINE_INFLUX_PORT=
PIPELINE_GRAFANA_PORT=

# Opportunity to override default passwords/names for standard services.
DATABASE_PW=
MESSAGE_QUEUE_COOKIE=
GRAFANA_ORG_NAME=

## Coordinator (api, scheduler, front-end client) - also to override exposed ports for conflicts/multiple systems.
PIPELINE_API_PORT=6001
PIPELINE_SCHEDULER_PORT=6002
PIPELINE_API_CLIENT_PORT=6101

# This needs to be the name of the host that the pipeline api container will run on.
PIPELINE_THUMBS_HOST=
PIPELINE_THUMBS_PORT=

## Mount an external volume - usually contains the task repositories.
EXTERNAL_DATA_VOLUME_1=
CONTAINER_DATA_VOLUME_1=
EXTERNAL_DATA_VOLUME_2=
CONTAINER_DATA_VOLUME_2=

##
## This section assumes a specific configuration of workers (four).  For a system with four workers, the host values
## can simply be set as appropriate.  To run with additional or fewer workers, modify the number of entries here
## and their corresponding section(s) in docker-compose.workers.yml.
##

## Worker values

# Same on all machines (assumes one worker per machine).  This value must match that value used in pipeline-worker-api
# options.sh file on each worker machine.
PIPELINE_WORKER_API_PORT=

# Enables the scheduler (with the port value above) to connect and distribute tasks to workers.

PIPELINE_WORKER1_HOST=
PIPELINE_WORKER2_HOST=
PIPELINE_WORKER3_HOST=
PIPELINE_WORKER4_HOST=

# Unique port for each worker client front-end.
PIPELINE_WORKER1_CLIENT_PORT=
PIPELINE_WORKER2_CLIENT_PORT=
PIPELINE_WORKER3_CLIENT_PORT=
PIPELINE_WORKER4_CLIENT_PORT=
